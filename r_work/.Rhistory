pa %>%
left_join(file_deets, by = c("project_id" = "project_id")) %>%
select(project_name.x, project_id, path, n_zip, n_xml, n_files, total_MB,
file_name, bytes)
pa %>%
left_join(file_deets, by = c("project_id" = "project_id", "path" = "path")) %>%
select(project_name.x, project_id, path, n_zip, n_xml, n_files, total_MB,
file_name, bytes)
pa <- potential_archives %>%
left_join(volume_all, by = c("project_id" = "project_id")) %>%
select(project_name.x, project_id, path, n_zip, n_xml, n_files, total_MB)
pa %>%
left_join(file_deets, by = c("project_id" = "project_id", "path" = "path")) %>%
select(project_name.x, project_id, path, n_zip, n_xml, n_files, total_MB,
file_name, bytes) %>%
rename(file_kb = bytes * 1000)
pa %>%
left_join(file_deets, by = c("project_id" = "project_id", "path" = "path")) %>%
select(project_name.x, project_id, path, n_zip, n_xml, n_files, total_MB,
file_name, bytes) %>%
mutate(byetes = bytes / 1000) %>%
rename(file_kb = bytes)
pa %>%
left_join(file_deets, by = c("project_id" = "project_id", "path" = "path")) %>%
select(project_name.x, project_id, path, n_zip, n_xml, n_files, total_MB,
file_name, bytes) %>%
mutate(bytes = bytes / 1000) %>%
rename(file_kb = bytes)
pa <- potential_archives %>%
left_join(volume_all, by = c("project_id" = "project_id")) %>%
select(project_name.x, project_id, path, n_zip, n_xml, n_files, total_MB)
file_deets <- big_inv %>%
filter(file_name %>% str_detect("NPRB\\.2[0-9]{3}\\.[0-9]{2}\\.[zip|xml]")) %>%
select(project_name, project_id, path, file_name, bytes)
potential_archvies <- pa %>%
left_join(file_deets, by = c("project_id" = "project_id", "path" = "path")) %>%
select(project_name.x, project_id, path, n_zip, n_xml, n_files, total_MB,
file_name, bytes) %>%
mutate(bytes = bytes / 1000) %>%
rename(file_kb = bytes)
write_csv(potential_archvies,
timestamp_filename(data_dir, "02_potential_archives"))
potential_archvies <- pa %>%
left_join(file_deets, by = c("project_id" = "project_id", "path" = "path")) %>%
select(project_name.x, project_id, path, n_zip, n_xml, n_files, total_MB,
file_name, bytes) %>%
mutate(bytes = bytes / 1000) %>%
rename(file_kb = bytes, project_name = project_name.x)
write_csv(potential_archvies,
timestamp_filename(data_dir, "02_potential_archives"))
potential_archvies <- pa %>%
left_join(file_deets, by = c("project_id" = "project_id", "path" = "path")) %>%
select(project_name.x, project_id, path, n_zip, n_xml, n_files, total_MB,
file_name, bytes) %>%
mutate(bytes = bytes / 1000000) %>%
rename(file_MB = bytes, project_name = project_name.x)
write_csv(potential_archvies,
timestamp_filename(data_dir, "02_potential_archives"))
pacman::p_load(tidyverse)
source("00_inventory_functions.R")
data_dir <- "data_out/"
big_inv <- read_csv(paste0(data_dir, "01_full_inventory.csv"))
potential_projects <- big_inv %>%
group_by(project_name) %>%
#  filter(file_name %>%
#           str_detect("NPRB\\.2[0-9]{3}\\.[0-9]{2}\\.[zip|xml]")) %>%
summarize(n_zip = sum(mimetype == "application/zip"),
n_xml = sum(mimetype == "application/xml")) %>%
filter(n_zip > 1,  n_xml > 1)
vol_arch <- volume_all %>%
ifelse(project_id %in% potential_archives$project_id,
volume_all$archive = 1,
vol_arch <- volume_all %>%
ifelse(project_id %in% potential_archives$project_id,
volume_all$archive=1,
vol_arch <- volume_all %>%
ifelse(project_id %in% potential_archives$project_id,
volume_all$archive <- 1,
volume_all$archive <- 0)
vol_arch <- volume_all
vol_arch$archive <- 0
ifelse(vol_arch$project_id %in% potential_archives$project_id,
volume_all$archive <- 1,
volume_all$archive <- 0)
vol_arch <- volume_all
# find all folders at least one zip and xml file that match the regex
potential_archives <- big_inv %>%
group_by(project_name, project_id, path) %>%
summarize(n_zip = sum(file_name %>%
str_detect("NPRB\\.2[0-9]{3}\\.[0-9]{2}\\.zip")),
n_xml = sum(file_name %>%
str_detect("NPRB\\.2[0-9]{3}\\.[0-9]{2}\\.xml"))) %>%
filter(n_zip > 0,  n_xml > 0)
# how many projects are there with zip and xml files?
projects_summary <- data.frame(
all_projects = length(unique(big_inv$project_name)),
potential_archives = length(unique(potential_archives$project_name))
)
volume_all <- get_volumes(big_inv)
vol_arch <- volume_all
vol_arch$archive <- 0
ifelse(vol_arch$project_id %in% potential_archives$project_id,
volume_all$archive <- 1,
volume_all$archive <- 0)
vol_arch$archive <-
ifelse(vol_arch$project_id %in% potential_archives$project_id, 1, 0)
View(vol_arch)
View(volume_all)
write_csv(vol_arch,
timestamp_filename(data_dir, "02_all_volumes"))
pacman::p_load(tidyverse, DBI, RPostgreSQL, keyring)
source("00_inventory_functions.R")
key_get("workspace_read", keyring = "dbs")
Sys.getenv("WORKSPACE_READ")
gc()
pacman::p_load(tidyverse, DBI, RPostgreSQL)#, keyring)
source("00_inventory_functions.R")
#key_get("workspace_read", keyring = "dbs")
# connect to the RW db
psql <- dbDriver("PostgreSQL")
key_get("workspace_read", keyring = "dbs")
Sys.getenv("WORKSPACE_READ")
con <- dbConnect(
drv = psql,
dbname = "research_workspace",
host = "oltp.db.axiomptk",
port = 5432,
password = Sys.getenv("WORKSPACE_READ"),
user = "workspace_read"
)
###############################################################################
########################### 03_archives_maybe.R ###############################
###############################################################################
library(tidyverse)
source("r_work/00_inventory_functions.R")
pacman::p_load(tidyverse, DBI, RPostgreSQL, keyring)
key_get("workspace_read", keyring = "dbs")
keyring_list()
keyring_list(dbs)
keyring_list("dbs")
key_list(dbs)
key_list("dbs")
key_list()
keyring_list()
key_list(keyring = dbs)
key_list(keyring = "dbs")
key_get(workspace_read, keyring="dbs")
key_get("workspace_read", keyring="dbs")
key_list(keyring="Login")
keyring_create(keyring = "axiom", password = "guardshoekeyperfectly")
key_set_with_value(service = "workspace_read", password = "ieQu5Ohmie7waefi8pha")
key_set_with_value(service = "rw_api_key", password = "zMmzunPWHV68Vg")
keyring_delete("dbs")
keyring_list()
key_list(keyring="axiom")
keyring_unlock("axiom")
key_list(keyring="axiom", service="rw_api_key")
key_get("workspace_read", keyring = "axiom")
key_get(service="workspace_read", keyring = "axiom")
key_get("workspace_read")
key_delete("workspace_read")
key_delete("rw_api_key")
key_set("workspace_read", keyring="axiom")
key_set("workspace_read", keyring="axiom")
key_set("rw_api_key", keyring="axiom")
keyring_list()
key_list()
key_list(keyring="axiom")
#' a folder named based on the NPRB project code (YYNN), where YY is
#' the year the project award was distributed and NN is the sequential project
#' number assigned by NPRB
#'
#' @param p_code the project code assigned by NPRB for the project that
#' created the data
#' @param f_id the file_id from the RW DB for the file to be downloaded
#' @param f_name the name of the file in the RW
#'
#' @noRd
wget_file_from_rw <- function(out_dir, f_id, f_name){
# given an output directory and the id and name of a file in the RW,
# use the RW API to pull the files down and save them in the output dir
file_url <- paste0("https://researchworkspace.com/files/",
as.character(f_id), "/", f_name)
#api_key <- Sys.getenv("RW_API_KEY")
api_key <- key_get("rw_api_key", keyring = "axiom")
wget_command <- paste0('wget --header "api-key: ', api_key,
'" -P ', out_dir, ' ', file_url)
system(wget_command)
}
pacman::p_load(tidyverse, DBI, RPostgreSQL)
source("00_inventory_functions.R")
# connect to the RW db
psql <- dbDriver("PostgreSQL")
con <- dbConnect(
drv = psql,
dbname = "research_workspace",
host = "oltp.db.axiomptk",
port = 5432,
password = Sys.getenv("WORKSPACE_READ"),
user = "workspace_read"
)
############################# 2025-05-08 ######################################
library(tidyverse)
df <- fread("data_out/02_potential_archives_2025-04-29_21-54-43.csv")
df <- read_csv("data_out/02_potential_archives_2025-04-29_21-54-43.csv")
View(df)
library(readr)
vols <- read_csv("data_out/02_all_volumes_2025-04-29_21-54-12.csv")
View(vols)
inv <- read_csv("data_out/01_full_inventory.csv")
sample_n(inv, 15)
names(inv)
archives <- inv |>
select(project_name, project_id, folder_name, folder_id) |>
unique()
archives <- inv |>
select(project_name, project_id) |>
unique()
psql <- dbDriver("PostgreSQL")
con <- dbConnect(
drv = psql,
dbname = "research_workspace",
host = "oltp.db.axiomptk",
port = 5432,
password = Sys.getenv("WORKSPACE_READ"),
user = "workspace_read"
)
############################# 2025-05-08 ######################################
pacman::p_load(tidyverse, DBI, RPostgreSQL)
psql <- dbDriver("PostgreSQL")
con <- dbConnect(
drv = psql,
dbname = "research_workspace",
host = "oltp.db.axiomptk",
port = 5432,
password = Sys.getenv("WORKSPACE_READ"),
user = "workspace_read"
)
proj_ids <- archives %>%
pull(project_id) %>%
paste(collapse = ",")
psql <- dbDriver("PostgreSQL")
con <- dbConnect(
drv = psql,
dbname = "research_workspace",
host = "oltp.db.axiomptk",
port = 5432,
password = Sys.getenv("WORKSPACE_READ"),
user = "workspace_read"
)
q <- paste0(
"SELECT doi, metadatapid, projectid as project_id, citation
FROM archivepackage
WHERE project_id IN (", proj_ids ,")"
)
archives_in_db <- dbGetQuery(con, q)
q <- paste0(
"SELECT doi, metadatapid, projectid as project_id, citation
FROM archivepackage
WHERE projectid IN (", proj_ids ,")"
)
archives_in_db <- dbGetQuery(con, q)
View(archives_in_db)
View(archives)
archives <- left_join(archives, archives_in_db, by = "project_id")
?order
archives <- left_join(archives, archives_in_db, by = "project_id") |>
order(project_name)
archives <- inv |>
select(project_name, project_id) |>
unique()
archives <- left_join(projects, archives_in_db, by = "project_id") |>
order(project_name)
projects <- inv |>
select(project_name, project_id) |>
unique()
archives <- left_join(projects, archives_in_db, by = "project_id") |>
order(project_name)
archives <- left_join(projects, archives_in_db, by = "project_id") |>
order(archvies$project_name)
archives <- left_join(projects, archives_in_db, by = "project_id") |>
order(archives$project_name)
archives <- left_join(projects, archives_in_db, by = "project_id") |>
arrange(project_name)
###############################################################################
########################### 03_archives_maybe.R ###############################
###############################################################################
library(tidyverse)
source("r_work/00_inventory_functions.R")
getwd()
source("00_inventory_functions.R")
setwd("../")
getwd()
source("r_work/00_inventory_functions.R")
newest_file <- sort(list.files("r_work/data_out",
full.names = TRUE)[str_detect(list.files("r_work/data_out"),
"02_potential_archives")],
decreasing = TRUE)[1]
archives <- read_csv(newest_file)
View(archives)
proj_sort <- count(archives, project_id, path, name="n_path") %>%
left_join(count(archives, project_id, name="n_proj"), by=join_by(project_id))
View(proj_sort)
base_path <- "./"
## Query RW DB to for projects that already have archives associated with them
pacman::p_load(DBI, RPostgreSQL)
potential_archives <- read_csv(newest_file)
## Query RW DB to for projects that already have archives associated with them
pacman::p_load(DBI, RPostgreSQL)
inv <- read_csv("data_out/01_full_inventory.csv")
inv <- read_csv("r_work/data_out/01_full_inventory.csv")
names(inv)
projects <- inv |>
select(project_name, project_id) |>
unique()
proj_ids <- projects %>%
pull(project_id) %>%
paste(collapse = ",")
psql <- dbDriver("PostgreSQL")
con <- dbConnect(
drv = psql,
dbname = "research_workspace",
host = "oltp.db.axiomptk",
port = 5432,
password = Sys.getenv("WORKSPACE_READ"),
user = "workspace_read"
)
q <- paste0(
"SELECT doi, metadatapid, projectid as project_id, citation
FROM archivepackage
WHERE projectid IN (", proj_ids ,")"
)
archives_in_db <- dbGetQuery(con, q)
archives <- left_join(projects, archives_in_db, by = "project_id") |>
arrange(project_name)
which(is.na(archives[c("doi", "metadatapid", "citation")]))
archives <- left_join(projects, archives_in_db, by = "project_id") |>
which(!is.na(c("doi", "metadatapid", "citation"))) |>
arrange(project_name)
archives <- left_join(projects, archives_in_db, by = "project_id") |>
which(archives[!is.na(c("doi", "metadatapid", "citation"))]) |>
arrange(project_name)
archives <- archives[which(is.na(archives[c("doi",
"metadatapid", "citation")]))]
archives <- archives[which(!is.na(archives[c("doi",
"metadatapid", "citation")]))]
archives <- archives[which(!is.na(archives[c("doi",
"metadatapid", "citation")])),]
archives_in_db <- dbGetQuery(con, q)
archives <- left_join(projects, archives_in_db, by = "project_id") |>
arrange(project_name)
archives_only <- archives[which(!is.na(archives[c("doi",
"metadatapid", "citation")])),]
View(archives_only)
archives_only <- which(!is.na(archives[c("doi",
"metadatapid", "citation")]))
archives_only <- archives[archives_only, ]
View(archives)
View(archives_in_db)
q <- paste0(
"SELECT projectid as project_id, citation, doi, metadatapid
FROM archivepackage
WHERE projectid IN (", proj_ids ,")"
)
archives_in_db <- dbGetQuery(con, q)
write_csv(archives_in_db, "r_work/data_out/03_archives_in_db.csv")
proj_vols <- read_csv("r_work/data_out/02_all_volumes_2025-04-29_21-54-12.csv")
names(proj_vols)[which(names(proj_vols) == "archive")] <- "new_archive"
p <- proj_vols |>
left_join(archives, by = "project_id", multiple = "all")
View(p)
p <- proj_vols |>
left_join(archives, by = "project_id", multiple = "all") |>
select(project_name.x, project_id, n_files, totl_MB,
new_archive, doi) |>
rename(project_name = project_name.x, rw_archive = doi)
p <- proj_vols |>
left_join(archives, by = "project_id", multiple = "all") |>
select(project_name.x, project_id, n_files, total_MB,
new_archive, doi) |>
rename(project_name = project_name.x, rw_archive = doi)
archive_inv <- p |>
filter(!(count(project_id >1 & is.na(doi))))
archive_inv <- p |>
filter(!(count(project_id >1 & is.na(rw_archive))))
archive_inv <- p |>
filter(!(count(project_id >1) & is.na(rw_archive)))
p |> filter(count(project_id) > 1)
p |> filter(count(project_name) > 1)
p |> count(project_name)
p |> count(project_name) |> filter(n > 1)
(p |> count(project_name) |> filter(n > 1))[project_name]
(p |> count(project_name) |> filter(n > 1))["project_name"]
(p |> count(project_name) |> filter(n > 1))["project_name"]
multi_archvies <- (p |> count(project_name) |> filter(n > 1))["project_name"]
archive_inv <- p |>
filter(project_name %in% multi_archvies$project_name)
View(archive_inv)
archive_inv <- p |>
filter(project_name %in% multi_archvies$project_name) |>
drop_na(rw_archive)
multi_archives <- (p |> count(project_name) |> filter(n > 1))["project_name"]
archive_inv <- p |>
filter(project_name %in% multi_archives$project_name) |>
drop_na(rw_archive)
archive_inventory <- p |>
filter(!project_name %in% multi_archives$project_name) |>
bind_rows(archive_inv)
View(archive_inventory)
m <- p |>
filter(project_name %in% (p |> count(project_name) |>
filter(n > 1))["project_name"]$project_name) |>
drop_na(rw_archive)
m == archive_inv
multi_archives <- p |>
filter(project_name %in% (p |> count(project_name) |>
filter(n > 1))["project_name"]$project_name) |>
drop_na(rw_archive)
View(multi_archives)
archive_inventory <- p |>
filter(!project_name %in% multi_archives$project_name) |>
bind_rows(multi_archives)
write_csv(archive_inventory, "r_work/data_out/03_archive_inventory.csv")
remove(list=(ls))
remove(list=ls())
###############################################################################
########################### 03_archives_maybe.R ###############################
###############################################################################
library(tidyverse)
source("r_work/00_inventory_functions.R")
getwd()
setwd("..")
source("r_work/00_inventory_functions.R")
newest_file <- sort(list.files("r_work/data_out",
full.names = TRUE)[str_detect(list.files("r_work/data_out"),
"02_potential_archives")],
decreasing = TRUE)[1]
potential_archives <- read_csv(newest_file)
proj_sort <- count(potential_archives, project_id, path, name="n_path") %>%
left_join(count(potential_archives, project_id, name="n_proj"), by=join_by(project_id))
base_path <- "./"
### rewrite this. I'm not sure that it's does what it needs to do
### that is, it finds the projects that have exactly one zip and one xml file
### and downloads those files. I also need it to get the zip and xml files from
### the projects that have more than one zip and xml file
for (i in 1:nrow(proj_sort)){
if (proj_sort$n_proj[i] == 2 && proj_sort$n_proj[i] == 2){
this_one <- archives |>
filter(project_id == proj_sort$project_id[i],
path == proj_sort$path[i])
dir_out <- str_split(this_one$project_name[1], " ")[[1]][1]
full_dir <- paste0(base_path, dir_out)
if(!dir.exists(full_dir)){
dir.create(full_dir)
}
#print(dir_out)
wget_file_from_rw(full_dir, this_one$file_id[1], this_one$file_name[1])
wget_file_from_rw(full_dir,  this_one$file_id[2], this_one$file_name[2])
} else {
ifelse(exists("tbd"), tbd <- rbind(tbd, this_one), tbd <- this_one)
}
}
### rewrite this. I'm not sure that it's does what it needs to do
### that is, it finds the projects that have exactly one zip and one xml file
### and downloads those files. I also need it to get the zip and xml files from
### the projects that have more than one zip and xml file
for (i in 1:nrow(proj_sort)){
if (proj_sort$n_proj[i] == 2 && proj_sort$n_proj[i] == 2){
this_one <- potential_archives |>
filter(project_id == proj_sort$project_id[i],
path == proj_sort$path[i])
dir_out <- str_split(this_one$project_name[1], " ")[[1]][1]
full_dir <- paste0(base_path, dir_out)
if(!dir.exists(full_dir)){
dir.create(full_dir)
}
#print(dir_out)
wget_file_from_rw(full_dir, this_one$file_id[1], this_one$file_name[1])
wget_file_from_rw(full_dir,  this_one$file_id[2], this_one$file_name[2])
} else {
ifelse(exists("tbd"), tbd <- rbind(tbd, this_one), tbd <- this_one)
}
}
View(proj_sort)
View(proj_sort)
View(proj_sort)
View(proj_sort)
View(proj_sort)
archive_inventory <- read_csv("r_work/data_out/03_archive_inventory.csv")
proj_vols <- read_csv("r_work/data_out/02_all_volumes_2025-04-29_21-54-12.csv")
View(proj_vols)
View(archive_inventory)
archive_inventory <- read_csv("r_work/data_out/03_archive_inventory.csv")
readr::archive_inventory <- read_csv("r_work/data_out/03_archive_inventory.csv")
###############################################################################
########################### 03_archives_maybe.R ###############################
###############################################################################
library(tidyverse)
archive_inventory <- read_csv("r_work/data_out/03_archive_inventory.csv")
getwd()
setwd("..")
archive_inventory <- read_csv("r_work/data_out/03_archive_inventory.csv")
View(archive_inventory)
nrow(unique(archive_inventory))
inv <- read_csv("r_work/data_out/01_full_inventory.csv")
names(inv)
length(unique(inv$project_name))
inv$project_id[which(str_starts(inv$project_name, "1202"))]
hmm <- inv$project_id[which(str_starts(inv$project_name, "1202"))]
k <- inv |> filter(project_id %ion% hmm)
k <- inv |> filter(project_id %in% hmm)
View(k)
